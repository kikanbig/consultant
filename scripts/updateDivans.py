#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–∏–≤–∞–Ω–æ–≤ –∏–∑ Excel —Ñ–∞–π–ª–∞
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–ª–∏–∞—Å—ã –¥–ª—è –±—Ä–µ–Ω–¥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π
"""

import openpyxl
import json
import re
from html import unescape

# –ê–ª–∏–∞—Å—ã –¥–ª—è –±—Ä–µ–Ω–¥–æ–≤
BRAND_ALIASES = {
    'VELUNA': ['veluna', '–≤–µ–ª—É–Ω–∞', '–≤–µ–ª—é–Ω–∞', '–∏–ª—É–Ω–∞', 'iluna', '–≤–∏–ª—É–Ω–∞'],
    'ELVA': ['elva', '—ç–ª–≤–∞', '—ç–ª—å–≤–∞', '–µ–ª–≤–∞', '–µ–ª—å–≤–∞'],
    'Rivalli': ['rivalli', '—Ä–∏–≤–∞–ª–ª–∏', '—Ä–∏–≤–∞–ª–∏', '—Ä–∏–≤–∞–ª–ª—ñ', 'revolut', '—Ä–µ–≤–æ–ª—é—Ç', '—Ä–µ–≤–æ–ª—é'],
    '–ú–µ–±–µ–ª—å–≥—Ä–∞–¥': ['–º–µ–±–µ–ª—å–≥—Ä–∞–¥', 'mebelgrad', '–º–µ–±–µ–ª–≥—Ä–∞–¥'],
    'Mio Tesoro': ['mio tesoro', '–º–∏–æ —Ç–µ—Å–æ—Ä–æ', '–º–∏–æ —Ç–µ–∑–æ—Ä–æ', '–º–∏–∞ —Ç–µ—Å–æ—Ä–æ', '–º–∏–∞ —Ç–µ–∑–æ—Ä–æ', 'mia tesoro', 'mio', '–º–∏–∞', '–º–∏–æ'],
    'Moon Trade': ['moon trade', '–º—É–Ω —Ç—Ä–µ–π–¥', '–º—É–Ω —Ç—Ä—ç–π–¥', 'moon', '–º—É–Ω'],
    'Anderssen': ['anderssen', '–∞–Ω–¥–µ—Ä—Å—Å–µ–Ω', '–∞–Ω–¥–µ—Ä—Å–µ–Ω', '–∞–Ω–¥–µ—Ä—Å–æ–Ω'],
    'Moon': ['moon', '–º—É–Ω', '–º—É–Ω'],
    'Trade': ['trade', '—Ç—Ä–µ–π–¥', '—Ç—Ä—ç–π–¥', '—Ç—Ä–µ–π—Ç'],
    'Woodcraft': ['woodcraft', '–≤—É–¥–∫—Ä–∞—Ñ—Ç', '–≤—É—Ç–∫—Ä–∞—Ñ—Ç'],
    'Leset': ['leset', '–ª–µ—Å–µ—Ç', '–ª–µ—Å—ç—Ç'],
    'Homeme': ['homeme', '—Ö–æ–º–º–∏', '—Ö–æ—É–º–º–∏', '—Ö–æ–º–º–µ'],
    'Askona': ['askona', '–∞—Å–∫–æ–Ω–∞'],
    'Lazurit': ['lazurit', '–ª–∞–∑—É—Ä–∏—Ç'],
    'Pushe': ['pushe', '–ø—É—à–µ', '–ø—É—à—ç', '–ø—É—à'],
    'First': ['first', '—Ñ–∏—Ä—Å—Ç', '—Ñ—ë—Ä—Å—Ç', '—Ñ–µ—Ä—Å—Ç']
}

# –°–ª–æ–≤–∞—Ä—å —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π
TRANSLIT_MAP = {
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ (—Ü–µ–ª—ã–µ —Å–ª–æ–≤–∞)
    'yuki': ['—é–∫–∫–∏', '—é–∫–∏', 'yukki'],
    'gizela': ['–≥–∏–∑–µ–ª–∞', '–≥–∏–∑–µ–ª–ª–∞'],
    'chianti': ['–∫—å—è–Ω—Ç–∏', '–∫–∏—è–Ω—Ç–∏', '–∫–∏–∞–Ω—Ç–∏', 'kyanti'],
    'miami': ['–º–∞–π–∞–º–∏', '–º–∞—è–º–∏', '–º–∏–∞–º–∏'],
    'aspen': ['–∞—Å–ø–µ–Ω', '–∞—Å–ø—ç–Ω'],
    'leyton': ['–ª–µ–π—Ç–æ–Ω', '–ª—ç–π—Ç–æ–Ω'],
    'evas': ['—ç–≤–∞—Å', '–µ–≤–∞—Å'],
    'sonni': ['—Å–æ–Ω–Ω–∏', '—Å–æ–Ω–∏'],
    'eloy': ['—ç–ª–æ–π', '–µ–ª–æ–π'],
    'vito': ['–≤–∏—Ç–æ', '–≤—ñ—Ç–æ'],
    'kubo': ['–∫—É–±–æ', '–∫—É–±–æ'],
    'bilbao': ['–±–∏–ª—å–±–∞–æ', '–±–∏–ª–±–∞–æ', '–±–∏–ª—å–±–∞–æ'],
    'pekin': ['–ø–µ–∫–∏–Ω', '–ø–µ–∫—ñ–Ω', 'beijing'],
    'aisti': ['–∞–π—Å—Ç–∏', '–∞–∏—Å—Ç–∏', 'isti'],
    'riemu': ['—Ä–∏–µ–º—É', '—Ä–∏—ç–º—É'],
    'tulisia': ['—Ç—É–ª–∏—Å–∏—è', '—Ç—É–ª–∏—Å—ñ—è'],
    'saari': ['—Å–∞–∞—Ä–∏', '—Å–∞–∞—Ä—ñ'],
    'unelma': ['—É–Ω–µ–ª—å–º–∞', '—É–Ω–µ–ª–º–∞'],
    'lintu': ['–ª–∏–Ω—Ç—É', '–ª—ñ–Ω—Ç—É'],
    'lira': ['–ª–∏—Ä–∞', '–ª—ñ—Ä–∞'],
    'tunne': ['—Ç—É–Ω–Ω–µ', '—Ç—É–Ω–µ'],
    'aurinko': ['–∞—É—Ä–∏–Ω–∫–æ', '–∞—É—Ä—ñ–Ω–∫–æ'],
    'velke': ['–≤–µ–ª–∫–µ', '–≤–µ–ª—å–∫—ç'],
    'tuuli': ['—Ç—É—É–ª–∏', '—Ç—É—É–ª—ñ'],
    'toivo': ['—Ç–æ–π–≤–æ', '—Ç–æ—ñ–≤–æ'],
    'jersey': ['–¥–∂–µ—Ä—Å–∏', '–¥–∂–µ—Ä—Å—ñ', '–¥–∂–µ—Ä—Å–∏'],
    'emma': ['—ç–º–º–∞', '–µ–º–º–∞'],
    'dijon': ['–¥–∏–∂–æ–Ω', '–¥—ñ–∂–æ–Ω'],
    'orleans': ['–æ—Ä–ª–µ–∞–Ω', '–æ—Ä–ª–µ–∞–Ω'],
    'parma': ['–ø–∞—Ä–º–∞', '–ø–∞—Ä–º–∞'],
    'discovery': ['–¥–∏—Å–∫–∞–≤–µ—Ä–∏', '–¥–∏—Å–∫–∞–≤–µ—Ä—ñ'],
    'porto': ['–ø–æ—Ä—Ç–æ', '–ø–æ—Ä—Ç–æ'],
    'somerset': ['—Å–æ–º–µ—Ä—Å–µ—Ç', '—Å–æ–º–µ—Ä—Å–µ—Ç'],
    'rimini': ['—Ä–∏–º–º–∏–Ω–∏', '—Ä–∏–º–∏–Ω–∏'],
    'valencia': ['–≤–∞–ª–µ–Ω—Å–∏—è', '–≤–∞–ª–µ–Ω—Å—ñ—è'],
    'montreal': ['–º–æ–Ω—Ä–µ–∞–ª—å', '–º–æ–Ω—Ä–µ–∞–ª', '–º–æ–Ω—Ç—Ä–µ–∞–ª—å'],
    'douglas': ['–¥—É–≥–ª–∞—Å', '–¥–∞–≥–ª–∞—Å'],
    # –û–±—â–∏–µ –±—É–∫–≤—ã (–¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤)
    'a': '–∞', 'b': '–±', 'v': '–≤', 'g': '–≥', 'd': '–¥', 'e': '–µ',
    'z': '–∑', 'i': '–∏', 'k': '–∫', 'l': '–ª', 'm': '–º', 'n': '–Ω',
    'o': '–æ', 'p': '–ø', 'r': '—Ä', 's': '—Å', 't': '—Ç', 'u': '—É',
    'f': '—Ñ', 'h': '—Ö', 'w': '–≤', 'y': '–π'
}

def generate_phonetic_variants(word):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è —Å–ª–æ–≤–∞
    """
    variants = set([word])
    
    # –ó–∞–º–µ–Ω—ã –¥–ª—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã—Ö —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
    phonetic_rules = [
        ('–µ', '—ç'), ('—ç', '–µ'),  # –µ/—ç
        ('–∏', '—ã'), ('—ã', '–∏'),  # –∏/—ã
        ('–æ', '–∞'), ('–∞', '–æ'),  # –æ/–∞ –≤ –±–µ–∑—É–¥–∞—Ä–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏
        ('—ë', '–µ'), ('–µ', '—ë'),  # —ë/–µ
        ('–π', '–∏'), ('–∏', '–π'),  # –π/–∏
        ('—Ü', '—Ç—Å'), ('—Ç—Å', '—Ü'),  # —Ü/—Ç—Å
        ('—á', '—Ç—à'), ('—Ç—à', '—á'),  # —á/—Ç—à
        ('—â', '—à—á'), ('—à—á', '—â'),  # —â/—à—á
        ('–¥–∂', '–∂'), ('–∂', '–¥–∂'),  # –¥–∂/–∂
        ('–Ω–Ω', '–Ω'), ('–Ω', '–Ω–Ω'),  # –¥–≤–æ–π–Ω—ã–µ —Å–æ–≥–ª–∞—Å–Ω—ã–µ
        ('–ª–ª', '–ª'), ('–ª', '–ª–ª'),
        ('–º–º', '–º'), ('–º', '–º–º'),
        ('—Å—Å', '—Å'), ('—Å', '—Å—Å'),
        ('—Ç—Ç', '—Ç'), ('—Ç', '—Ç—Ç'),
    ]
    
    for old, new in phonetic_rules:
        if old in word:
            variants.add(word.replace(old, new))
    
    return variants

def generate_model_aliases(model_name):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –∞–ª–∏–∞—Å—ã –¥–ª—è –º–æ–¥–µ–ª–∏
    """
    if not model_name:
        return []
    
    aliases = set()
    model_lower = model_name.lower().strip()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
    aliases.add(model_lower)
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
    words = model_lower.split()
    
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
    for word in words:
        # –§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        for variant in generate_phonetic_variants(word):
            aliases.add(variant)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
            other_words = [w for w in words if w != word]
            if other_words:
                aliases.add(' '.join([variant] + other_words))
                aliases.add(' '.join(other_words + [variant]))
    
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ –∏–∑ TRANSLIT_MAP
    for word in words:
        if word in TRANSLIT_MAP and isinstance(TRANSLIT_MAP[word], list):
            # –≠—Ç–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Å–ª—É—á–∞–π - –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
            for variant in TRANSLIT_MAP[word]:
                aliases.add(variant)
                
                # –§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
                for phonetic in generate_phonetic_variants(variant):
                    aliases.add(phonetic)
                
                # –¢–∞–∫–∂–µ –¥–æ–±–∞–≤–ª—è–µ–º —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
                other_words = [w for w in words if w != word]
                if other_words:
                    for variant_word in TRANSLIT_MAP[word]:
                        aliases.add(' '.join([variant_word] + other_words))
                        aliases.add(' '.join(other_words + [variant_word]))
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –æ—Ç–¥–µ–ª—å–Ω–æ (–æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)
    if words:
        first_word = words[0]
        aliases.add(first_word)
        
        # –§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ–≤–∞
        for variant in generate_phonetic_variants(first_word):
            aliases.add(variant)
        
        # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ–≤–∞
        if first_word in TRANSLIT_MAP and isinstance(TRANSLIT_MAP[first_word], list):
            for variant in TRANSLIT_MAP[first_word]:
                aliases.add(variant)
                for phonetic in generate_phonetic_variants(variant):
                    aliases.add(phonetic)
    
    # –£–±–∏—Ä–∞–µ–º —Å—É—Ñ—Ñ–∏–∫—Å—ã —Ç–∏–ø–∞ "-4", "-2" –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –±–∞–∑–æ–≤–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é
    for word in words:
        base_word = re.sub(r'-?\d+$', '', word)
        if base_word and base_word != word and len(base_word) >= 3:
            aliases.add(base_word)
            
            # –§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –±–∞–∑–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞
            for variant in generate_phonetic_variants(base_word):
                aliases.add(variant)
            
            # –ò —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞
            if base_word in TRANSLIT_MAP and isinstance(TRANSLIT_MAP[base_word], list):
                for variant in TRANSLIT_MAP[base_word]:
                    aliases.add(variant)
                    for phonetic in generate_phonetic_variants(variant):
                        aliases.add(phonetic)
    
    # –ò—â–µ–º –ª–∞—Ç–∏–Ω—Å–∫–∏–π –∫–ª—é—á –¥–ª—è –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞
    for word in words:
        for lat_key, cyr_variants in TRANSLIT_MAP.items():
            if isinstance(cyr_variants, list) and word in cyr_variants:
                aliases.add(lat_key)
                other_words = [w for w in words if w != word]
                if other_words:
                    aliases.add(' '.join([lat_key] + other_words))
                    aliases.add(' '.join(other_words + [lat_key]))
    
    # –£–±–∏—Ä–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–ª–∏–∞—Å—ã (–º–µ–Ω—å—à–µ 3 —Å–∏–º–≤–æ–ª–æ–≤)
    aliases = {a for a in aliases if len(a) >= 3}
    
    return sorted(list(aliases))

def generate_article_aliases(article_code):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–ª–∏–∞—Å—ã –¥–ª—è –∞—Ä—Ç–∏–∫—É–ª–∞ (–∫–æ–¥ —Ç–æ–≤–∞—Ä–∞)
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç –ø–æ –æ–¥–Ω–æ–π —Ü–∏—Ñ—Ä–µ: "–æ–¥–∏–Ω –Ω–æ–ª—å –Ω–æ–ª—å —Å–µ–º—å —Å–µ–º—å –æ–¥–∏–Ω –¥–≤–∞ —Å–µ–º—å"
    """
    if not article_code:
        return []
    
    # –°–ª–æ–≤–∞—Ä—å –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è —Ü–∏—Ñ—Ä
    digit_names = {
        '0': ['–Ω–æ–ª—å', '–Ω—É–ª—å'],
        '1': ['–æ–¥–∏–Ω', '—Ä–∞–∑', '–∞–¥–∏–Ω'],
        '2': ['–¥–≤–∞', '–¥–≤–æ–π–∫–∞'],
        '3': ['—Ç—Ä–∏', '—Ç—Ä–æ–π–∫–∞'],
        '4': ['—á–µ—Ç—ã—Ä–µ', '—á–µ—Ç–≤–µ—Ä–∫–∞', '—á–∏—Ç—ã—Ä–µ'],
        '5': ['–ø—è—Ç—å', '–ø—è—Ç–µ—Ä–∫–∞', '–ø—å—è—Ç—å'],
        '6': ['—à–µ—Å—Ç—å', '—à–µ—Å—Ç–µ—Ä–∫–∞', '—à—ç—Å—Ç—å'],
        '7': ['—Å–µ–º—å', '—Å–µ–º–µ—Ä–∫–∞', '—Å–µ–º'],
        '8': ['–≤–æ—Å–µ–º—å', '–≤–æ—Å—å–º–µ—Ä–∫–∞', '–≤–æ—Å–µ–º'],
        '9': ['–¥–µ–≤—è—Ç—å', '–¥–µ–≤—è—Ç–∫–∞', '–¥–∏–≤—è—Ç—å']
    }
    
    aliases = set()
    code_str = str(article_code).strip()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
    aliases.add(code_str)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ –ø–æ —Ü–∏—Ñ—Ä–∞–º
    # –ù–∞–ø—Ä–∏–º–µ—Ä: "10077127" ‚Üí "–æ–¥–∏–Ω –Ω–æ–ª—å –Ω–æ–ª—å —Å–µ–º—å —Å–µ–º—å –æ–¥–∏–Ω –¥–≤–∞ —Å–µ–º—å"
    for i in range(len(code_str)):
        digit = code_str[i]
        if digit in digit_names:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Å–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–π
            # –≠—Ç–æ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –ø–æ–∏—Å–∫–∞
            pass
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å –ø—Ä–æ–±–µ–ª–∞–º–∏ –º–µ–∂–¥—É —Ü–∏—Ñ—Ä–∞–º–∏
    spaced = ' '.join(code_str)
    aliases.add(spaced)
    
    return sorted(list(aliases))

def generate_brand_aliases(brand_name):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–ª–∏–∞—Å—ã –¥–ª—è –±—Ä–µ–Ω–¥–∞
    """
    if not brand_name:
        return []
    
    brand_clean = brand_name.strip()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if brand_clean in BRAND_ALIASES:
        return BRAND_ALIASES[brand_clean]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    for key, aliases in BRAND_ALIASES.items():
        if key.lower() in brand_clean.lower() or brand_clean.lower() in key.lower():
            return aliases
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–µ –∞–ª–∏–∞—Å—ã
    return [brand_clean.lower()]

def parse_excel_to_json(excel_path, output_path):
    """
    –ü–∞—Ä—Å–∏—Ç Excel —Ñ–∞–π–ª –∏ —Å–æ–∑–¥–∞—ë—Ç JSON —Å –∞–ª–∏–∞—Å–∞–º–∏
    """
    print(f"üìñ –ß–∏—Ç–∞—é —Ñ–∞–π–ª: {excel_path}")
    
    wb = openpyxl.load_workbook(excel_path, data_only=True)
    ws = wb['–ú—è–≥–∫–∞—è –º–µ–±–µ–ª—å']
    
    divans = []
    
    # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞—á–∏–Ω–∞—è —Å–æ —Å—Ç—Ä–æ–∫–∏ 8
    for row in range(8, ws.max_row + 1):
        kod = ws.cell(row, 1).value  # A - –∫–æ–¥ —Ç–æ–≤–∞—Ä–∞
        name = ws.cell(row, 2).value  # B - –Ω–∞–∑–≤–∞–Ω–∏–µ
        description = ws.cell(row, 4).value  # D - –æ–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        
        if kod and name:
            # –û—á–∏—â–∞–µ–º HTML –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
            if description:
                description = re.sub(r'<[^<]+?>', '', str(description))
                description = unescape(description)
                description = re.sub(r'\s+', ' ', description).strip()
            
            # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –±—Ä–µ–Ω–¥–∞ –∏ –º–æ–¥–µ–ª–∏
            name_str = str(name)
            
            # –£–±–∏—Ä–∞–µ–º —Ç–∏–ø –º–µ–±–µ–ª–∏ –≤ –Ω–∞—á–∞–ª–µ
            pattern = r'^(–î–∏–≤–∞–Ω\s+(—É–≥–ª–æ–≤–æ–π\s+|–ü-–æ–±—Ä–∞–∑–Ω—ã–π\s+)?|–ö—Ä–µ—Å–ª–æ(-–∫—Ä–æ–≤–∞—Ç—å|-—Ä–µ–∫–ª–∞–π–Ω–µ—Ä|\s+–º—è–≥–∫–æ–µ)?\s+|–ö–æ–º–ø–ª–µ–∫—Ç\s+.*?\s+|–ú–æ–¥—É–ª—å\s+–º—è–≥–∫–∏–π\s+|–ü—É—Ñ(-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä)?\s+|–¢–∞—Ö—Ç–∞(\s+—É–≥–ª–æ–≤–∞—è)?\s+|–£–≥–æ–ª–æ–∫\s+.*?\s+|–°–∫–∞–º—å—è\s+.*?\s+|–û—Ç—Ç–æ–º–∞–Ω–∫–∞\s+)'
            cleaned_name = re.sub(pattern, '', name_str, flags=re.IGNORECASE).strip()
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è "Mio Tesoro" (–¥–≤—É—Ö—Å–ª–æ–≤–Ω—ã–π –±—Ä–µ–Ω–¥)
            brand = ""
            model = ""
            
            if cleaned_name.startswith('Mio Tesoro') or cleaned_name.startswith('Mio tesoro'):
                brand = 'Mio Tesoro'
                model = cleaned_name[10:].strip()  # –£–±–∏—Ä–∞–µ–º "Mio Tesoro"
                # –£–±–∏—Ä–∞–µ–º –≤—Å—ë –ø–æ—Å–ª–µ —Å–∫–æ–±–∫–∏
                if '(' in model:
                    model = model[:model.index('(')].strip()
            elif cleaned_name.startswith('Moon Trade') or cleaned_name.startswith('Moon trade'):
                brand = 'Moon Trade'
                model = cleaned_name[10:].strip()
                if '(' in model:
                    model = model[:model.index('(')].strip()
            else:
                # –û–±—ã—á–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è –æ–¥–Ω–æ—Å–ª–æ–∂–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤
                match = re.search(r'^([A-Za-z–ê-–Ø–∞-—è\s]+?)\s+([A-Za-z–ê-–Ø–∞-—è0-9\s\-]+?)(?:\s*\(|$)', cleaned_name)
                if match:
                    brand = match.group(1).strip()
                    model = match.group(2).strip()
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–ª–∏–∞—Å—ã
            brand_aliases = generate_brand_aliases(brand)
            model_aliases = generate_model_aliases(model)
            article_aliases = generate_article_aliases(kod)
            
            divans.append({
                'kod': str(kod),
                'name': name_str,
                'brand': brand,
                'model': model,
                'brandAliases': brand_aliases,
                'modelAliases': model_aliases,
                'articleAliases': article_aliases,
                'description': description or '–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'
            })
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({'divans': divans}, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(divans)} –¥–∏–≤–∞–Ω–æ–≤ –≤ {output_path}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–ª–∏–∞—Å–æ–≤:")
    total_brand_aliases = sum(len(d['brandAliases']) for d in divans)
    total_model_aliases = sum(len(d['modelAliases']) for d in divans)
    total_article_aliases = sum(len(d['articleAliases']) for d in divans)
    print(f"   –í—Å–µ–≥–æ –∞–ª–∏–∞—Å–æ–≤ –±—Ä–µ–Ω–¥–æ–≤: {total_brand_aliases}")
    print(f"   –í—Å–µ–≥–æ –∞–ª–∏–∞—Å–æ–≤ –º–æ–¥–µ–ª–µ–π: {total_model_aliases}")
    print(f"   –í—Å–µ–≥–æ –∞–ª–∏–∞—Å–æ–≤ –∞—Ä—Ç–∏–∫—É–ª–æ–≤: {total_article_aliases}")
    
    # –ü—Ä–∏–º–µ—Ä—ã
    print(f"\nüìù –ü—Ä–∏–º–µ—Ä—ã (–ø–µ—Ä–≤—ã–µ 3):")
    for i, divan in enumerate(divans[:3], 1):
        print(f"\n{i}. {divan['name'][:60]}")
        print(f"   –ö–æ–¥: {divan['kod']}")
        print(f"   –ë—Ä–µ–Ω–¥: {divan['brand']}")
        print(f"   –ê–ª–∏–∞—Å—ã –±—Ä–µ–Ω–¥–∞: {', '.join(divan['brandAliases'][:5])}")
        print(f"   –ú–æ–¥–µ–ª—å: {divan['model']}")
        print(f"   –ê–ª–∏–∞—Å—ã –º–æ–¥–µ–ª–∏ ({len(divan['modelAliases'])} —à—Ç): {', '.join(divan['modelAliases'][:8])}")
        if len(divan['modelAliases']) > 8:
            print(f"      ... –∏ –µ—â–µ {len(divan['modelAliases']) - 8} –∞–ª–∏–∞—Å–æ–≤")

if __name__ == '__main__':
    import os
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)
    excel_path = os.path.join(project_dir, '–§–∞–π–ª –¥–ª—è –¥–∏–≤–∞–Ω–æ–≤', '–î–∏–≤–∞–Ω—ã, –∫—Ä–µ—Å—Å–ª–∞, –º–∞—Ç—Ä–∞—Å—ã —Ä–æ–∑–Ω–∏—Ü–∞ (1).xlsx')
    output_path = os.path.join(project_dir, 'src', 'data', 'divans.json')
    
    print("üöÄ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–∏–≤–∞–Ω–æ–≤\n")
    parse_excel_to_json(excel_path, output_path)
    print("\n‚ú® –ì–æ—Ç–æ–≤–æ!")

